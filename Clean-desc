import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize

# Ensure NLTK resources are available
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)

# Common filler phrases to remove
FILLER_PHRASES = [
    "official site", "welcome to", "we provide", "our mission is", "learn more about",
    "serving customers", "offering", "high quality", "for all your", "trusted name in",
    "since", "years of experience", "at the heart of", "dedicated to"
]

def clean_summary(text):
    if not isinstance(text, str):
        return ""

    text = text.lower()
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'[^a-z0-9\s.,-]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()

    # Remove filler phrases
    for phrase in FILLER_PHRASES:
        text = text.replace(phrase, '')

    # Tokenize into sentences, keep the most informative one
    sentences = sent_tokenize(text)
    keywords = []
    stop_words = set(stopwords.words("english"))

    for sent in sentences:
        words = word_tokenize(sent)
        filtered = [w for w in words if w not in stop_words and len(w) > 2]
        if len(filtered) > len(keywords):
            keywords = filtered

    return " ".join(keywords)
